{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d08e230",
   "metadata": {},
   "source": [
    "# LLM-powered UML Class Diagram Generator\n",
    "Generate UML class diagrams from natural language problem specifications using Gemini API, with modular prompt engineering and SOLID principle evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c65364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Required Libraries\n",
    "import requests\n",
    "import json\n",
    "from IPython.display import Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Insert your Gemini API Key below\n",
    "GEMINI_API_KEY = \"AIzaSyC-G81Hhcw9HduAmGboYXBgDx_szPcNqLk\"\n",
    "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317ddee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt Engineering Module\n",
    "def build_prompt(problem_spec, shot_style=\"zero-shot\", examples=None, output_format=\"PlantUML\"):\n",
    "    base_task = f\"Generate a UML class diagram for the following specification, using {output_format} syntax. Ensure the output follows SOLID principles. Problem Specification: {problem_spec}\"\n",
    "    if shot_style == \"zero-shot\":\n",
    "        prompt = base_task\n",
    "    elif shot_style == \"one-shot\" and examples:\n",
    "        prompt = f\"\"\"Here is an example UML class diagram: {examples[0]} \n",
    "        Now, {base_task}\n",
    "\"\"\"\n",
    "    elif shot_style == \"few-shot\" and examples:\n",
    "        few_shot_examples = \"\"\"\n",
    "\n",
    "\".join([f\"Example {i+1}:\n",
    "{ex}\" for i, ex in enumerate(examples)])\n",
    "        prompt = f\"{few_shot_examples}\n",
    "\n",
    "Now, {base_task}\n",
    "\"\"\"\n",
    "    else:\n",
    "        prompt = base_task\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a01dcc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gemini API Request\n",
    "def gemini_generate_class_diagram(prompt):\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"contents\": [{\"parts\": [{\"text\": prompt}]}]\n",
    "    }\n",
    "    response = requests.post(\n",
    "        f\"{GEMINI_API_URL}?key={GEMINI_API_KEY}\",\n",
    "        headers=headers,\n",
    "        data=json.dumps(payload)\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        candidates = response.json().get(\"candidates\", [])\n",
    "        if candidates:\n",
    "            return candidates[0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Error:\", response.text)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5fde80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example Integration\n",
    "EXAMPLES = [\n",
    "    '''\n",
    "@startuml\n",
    "class Customer {\n",
    "  - name: String\n",
    "  - email: String\n",
    "  + getProfile()\n",
    "}\n",
    "class Order {\n",
    "  - orderId: int\n",
    "  - date: Date\n",
    "  + calculateTotal()\n",
    "}\n",
    "Customer \"1\" -- \"*\" Order\n",
    "@enduml\n",
    "''',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9f7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Class Diagram Evaluation Stub\n",
    "def evaluate_solid(plantuml_code):\n",
    "    feedback = []\n",
    "    if \"interface\" in plantuml_code:\n",
    "        feedback.append(\"Interface Segregation Principle: Detected interface usage.\")\n",
    "    if \"<|--\" in plantuml_code:\n",
    "        feedback.append(\"Liskov Substitution Principle: Inheritance detected.\")\n",
    "    if \"abstract\" in plantuml_code or \"interface\" in plantuml_code:\n",
    "        feedback.append(\"Open-Closed Principle: Abstractions detected.\")\n",
    "    return feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eecc3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Interactive Generation Function\n",
    "def generate_class_diagram(problem_spec, shot_style=\"zero-shot\", examples=None):\n",
    "    prompt = build_prompt(problem_spec, shot_style, examples)\n",
    "    diagram = gemini_generate_class_diagram(prompt)\n",
    "    evaluation = evaluate_solid(diagram)\n",
    "    print(\"Generated PlantUML Diagram:\", diagram)\n",
    "    print(\"SOLID Principles Evaluation:\")\n",
    "    for fb in evaluation:\n",
    "        print(\"- \" + fb)\n",
    "    return diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6a12e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {\n",
      "  \"error\": {\n",
      "    \"code\": 404,\n",
      "    \"message\": \"models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\",\n",
      "    \"status\": \"NOT_FOUND\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m shot_style \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone-shot\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Alternatives: \"zero-shot\", \"few-shot\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m examples_to_use \u001b[38;5;241m=\u001b[39m EXAMPLES[:\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m diagram \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_class_diagram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem_specification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot_style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples_to_use\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m, in \u001b[0;36mgenerate_class_diagram\u001b[1;34m(problem_spec, shot_style, examples)\u001b[0m\n\u001b[0;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m build_prompt(problem_spec, shot_style, examples)\n\u001b[0;32m      4\u001b[0m diagram \u001b[38;5;241m=\u001b[39m gemini_generate_class_diagram(prompt)\n\u001b[1;32m----> 5\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_solid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiagram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated PlantUML Diagram:\u001b[39m\u001b[38;5;124m\"\u001b[39m, diagram)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSOLID Principles Evaluation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m, in \u001b[0;36mevaluate_solid\u001b[1;34m(plantuml_code)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_solid\u001b[39m(plantuml_code):\n\u001b[0;32m      3\u001b[0m     feedback \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minterface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mplantuml_code\u001b[49m:\n\u001b[0;32m      5\u001b[0m         feedback\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterface Segregation Principle: Detected interface usage.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m plantuml_code:\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage Example\n",
    "problem_specification = \"A hospital management system with patients, doctors, wards, and treatment records.\"\n",
    "shot_style = \"one-shot\"  # Alternatives: \"zero-shot\", \"few-shot\"\n",
    "examples_to_use = EXAMPLES[:1]\n",
    "diagram = generate_class_diagram(problem_specification, shot_style, examples_to_use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c3371a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'models': [{'name': 'models/embedding-gecko-001', 'version': '001', 'displayName': 'Embedding Gecko', 'description': 'Obtain a distributed representation of a text.', 'inputTokenLimit': 1024, 'outputTokenLimit': 1, 'supportedGenerationMethods': ['embedText', 'countTextTokens']}, {'name': 'models/gemini-1.5-pro-latest', 'version': '001', 'displayName': 'Gemini 1.5 Pro Latest', 'description': 'Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.', 'inputTokenLimit': 2000000, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-1.5-pro-002', 'version': '002', 'displayName': 'Gemini 1.5 Pro 002', 'description': 'Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.', 'inputTokenLimit': 2000000, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-1.5-pro', 'version': '001', 'displayName': 'Gemini 1.5 Pro', 'description': 'Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', 'inputTokenLimit': 2000000, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-1.5-flash-latest', 'version': '001', 'displayName': 'Gemini 1.5 Flash Latest', 'description': 'Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', 'inputTokenLimit': 1000000, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-1.5-flash', 'version': '001', 'displayName': 'Gemini 1.5 Flash', 'description': 'Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', 'inputTokenLimit': 1000000, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-1.5-flash-002', 'version': '002', 'displayName': 'Gemini 1.5 Flash 002', 'description': 'Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.', 'inputTokenLimit': 1000000, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-1.5-flash-8b', 'version': '001', 'displayName': 'Gemini 1.5 Flash-8B', 'description': 'Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', 'inputTokenLimit': 1000000, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['createCachedContent', 'generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-1.5-flash-8b-001', 'version': '001', 'displayName': 'Gemini 1.5 Flash-8B 001', 'description': 'Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', 'inputTokenLimit': 1000000, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['createCachedContent', 'generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-1.5-flash-8b-latest', 'version': '001', 'displayName': 'Gemini 1.5 Flash-8B Latest', 'description': 'Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', 'inputTokenLimit': 1000000, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['createCachedContent', 'generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-2.5-pro-preview-03-25', 'version': '2.5-preview-03-25', 'displayName': 'Gemini 2.5 Pro Preview 03-25', 'description': 'Gemini 2.5 Pro Preview 03-25', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.5-flash-preview-05-20', 'version': '2.5-preview-05-20', 'displayName': 'Gemini 2.5 Flash Preview 05-20', 'description': 'Preview release (April 17th, 2025) of Gemini 2.5 Flash', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.5-flash', 'version': '001', 'displayName': 'Gemini 2.5 Flash', 'description': 'Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.5-flash-lite-preview-06-17', 'version': '2.5-preview-06-17', 'displayName': 'Gemini 2.5 Flash-Lite Preview 06-17', 'description': 'Preview release (June 11th, 2025) of Gemini 2.5 Flash-Lite', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.5-pro-preview-05-06', 'version': '2.5-preview-05-06', 'displayName': 'Gemini 2.5 Pro Preview 05-06', 'description': 'Preview release (May 6th, 2025) of Gemini 2.5 Pro', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.5-pro-preview-06-05', 'version': '2.5-preview-06-05', 'displayName': 'Gemini 2.5 Pro Preview', 'description': 'Preview release (June 5th, 2025) of Gemini 2.5 Pro', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.5-pro', 'version': '2.5', 'displayName': 'Gemini 2.5 Pro', 'description': 'Stable release (June 17th, 2025) of Gemini 2.5 Pro', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.0-flash-exp', 'version': '2.0', 'displayName': 'Gemini 2.0 Flash Experimental', 'description': 'Gemini 2.0 Flash Experimental', 'inputTokenLimit': 1048576, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'bidiGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-2.0-flash', 'version': '2.0', 'displayName': 'Gemini 2.0 Flash', 'description': 'Gemini 2.0 Flash', 'inputTokenLimit': 1048576, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-2.0-flash-001', 'version': '2.0', 'displayName': 'Gemini 2.0 Flash 001', 'description': 'Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.', 'inputTokenLimit': 1048576, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-2.0-flash-exp-image-generation', 'version': '2.0', 'displayName': 'Gemini 2.0 Flash (Image Generation) Experimental', 'description': 'Gemini 2.0 Flash (Image Generation) Experimental', 'inputTokenLimit': 1048576, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'bidiGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-2.0-flash-lite-001', 'version': '2.0', 'displayName': 'Gemini 2.0 Flash-Lite 001', 'description': 'Stable version of Gemini 2.0 Flash-Lite', 'inputTokenLimit': 1048576, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-2.0-flash-lite', 'version': '2.0', 'displayName': 'Gemini 2.0 Flash-Lite', 'description': 'Gemini 2.0 Flash-Lite', 'inputTokenLimit': 1048576, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-2.0-flash-preview-image-generation', 'version': '2.0', 'displayName': 'Gemini 2.0 Flash Preview Image Generation', 'description': 'Gemini 2.0 Flash Preview Image Generation', 'inputTokenLimit': 32768, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2}, {'name': 'models/gemini-2.0-flash-lite-preview-02-05', 'version': 'preview-02-05', 'displayName': 'Gemini 2.0 Flash-Lite Preview 02-05', 'description': 'Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite', 'inputTokenLimit': 1048576, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-2.0-flash-lite-preview', 'version': 'preview-02-05', 'displayName': 'Gemini 2.0 Flash-Lite Preview', 'description': 'Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite', 'inputTokenLimit': 1048576, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 40, 'maxTemperature': 2}, {'name': 'models/gemini-2.0-pro-exp', 'version': '2.5-exp-03-25', 'displayName': 'Gemini 2.0 Pro Experimental', 'description': 'Experimental release (March 25th, 2025) of Gemini 2.5 Pro', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.0-pro-exp-02-05', 'version': '2.5-exp-03-25', 'displayName': 'Gemini 2.0 Pro Experimental 02-05', 'description': 'Experimental release (March 25th, 2025) of Gemini 2.5 Pro', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-exp-1206', 'version': '2.5-exp-03-25', 'displayName': 'Gemini Experimental 1206', 'description': 'Experimental release (March 25th, 2025) of Gemini 2.5 Pro', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.0-flash-thinking-exp-01-21', 'version': '2.5-preview-05-20', 'displayName': 'Gemini 2.5 Flash Preview 05-20', 'description': 'Preview release (April 17th, 2025) of Gemini 2.5 Flash', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.0-flash-thinking-exp', 'version': '2.5-preview-05-20', 'displayName': 'Gemini 2.5 Flash Preview 05-20', 'description': 'Preview release (April 17th, 2025) of Gemini 2.5 Flash', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.0-flash-thinking-exp-1219', 'version': '2.5-preview-05-20', 'displayName': 'Gemini 2.5 Flash Preview 05-20', 'description': 'Preview release (April 17th, 2025) of Gemini 2.5 Flash', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/gemini-2.5-flash-preview-tts', 'version': 'gemini-2.5-flash-exp-tts-2025-05-19', 'displayName': 'Gemini 2.5 Flash Preview TTS', 'description': 'Gemini 2.5 Flash Preview TTS', 'inputTokenLimit': 8192, 'outputTokenLimit': 16384, 'supportedGenerationMethods': ['countTokens', 'generateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2}, {'name': 'models/gemini-2.5-pro-preview-tts', 'version': 'gemini-2.5-pro-preview-tts-2025-05-19', 'displayName': 'Gemini 2.5 Pro Preview TTS', 'description': 'Gemini 2.5 Pro Preview TTS', 'inputTokenLimit': 8192, 'outputTokenLimit': 16384, 'supportedGenerationMethods': ['countTokens', 'generateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2}, {'name': 'models/learnlm-2.0-flash-experimental', 'version': '2.0', 'displayName': 'LearnLM 2.0 Flash Experimental', 'description': 'LearnLM 2.0 Flash Experimental', 'inputTokenLimit': 1048576, 'outputTokenLimit': 32768, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2}, {'name': 'models/gemma-3-1b-it', 'version': '001', 'displayName': 'Gemma 3 1B', 'inputTokenLimit': 32768, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 64}, {'name': 'models/gemma-3-4b-it', 'version': '001', 'displayName': 'Gemma 3 4B', 'inputTokenLimit': 32768, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 64}, {'name': 'models/gemma-3-12b-it', 'version': '001', 'displayName': 'Gemma 3 12B', 'inputTokenLimit': 32768, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 64}, {'name': 'models/gemma-3-27b-it', 'version': '001', 'displayName': 'Gemma 3 27B', 'inputTokenLimit': 131072, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 64}, {'name': 'models/gemma-3n-e4b-it', 'version': '001', 'displayName': 'Gemma 3n E4B', 'inputTokenLimit': 8192, 'outputTokenLimit': 2048, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 64}, {'name': 'models/gemma-3n-e2b-it', 'version': '001', 'displayName': 'Gemma 3n E2B', 'inputTokenLimit': 8192, 'outputTokenLimit': 2048, 'supportedGenerationMethods': ['generateContent', 'countTokens'], 'temperature': 1, 'topP': 0.95, 'topK': 64}, {'name': 'models/gemini-2.5-flash-lite', 'version': '001', 'displayName': 'Gemini 2.5 Flash-Lite', 'description': 'Stable verion of Gemini 2.5 Flash-Lite, released in July of 2025', 'inputTokenLimit': 1048576, 'outputTokenLimit': 65536, 'supportedGenerationMethods': ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], 'temperature': 1, 'topP': 0.95, 'topK': 64, 'maxTemperature': 2, 'thinking': True}, {'name': 'models/embedding-001', 'version': '001', 'displayName': 'Embedding 001', 'description': 'Obtain a distributed representation of a text.', 'inputTokenLimit': 2048, 'outputTokenLimit': 1, 'supportedGenerationMethods': ['embedContent']}, {'name': 'models/text-embedding-004', 'version': '004', 'displayName': 'Text Embedding 004', 'description': 'Obtain a distributed representation of a text.', 'inputTokenLimit': 2048, 'outputTokenLimit': 1, 'supportedGenerationMethods': ['embedContent']}, {'name': 'models/gemini-embedding-exp-03-07', 'version': 'exp-03-07', 'displayName': 'Gemini Embedding Experimental 03-07', 'description': 'Obtain a distributed representation of a text.', 'inputTokenLimit': 8192, 'outputTokenLimit': 1, 'supportedGenerationMethods': ['embedContent', 'countTextTokens', 'countTokens']}, {'name': 'models/gemini-embedding-exp', 'version': 'exp-03-07', 'displayName': 'Gemini Embedding Experimental', 'description': 'Obtain a distributed representation of a text.', 'inputTokenLimit': 8192, 'outputTokenLimit': 1, 'supportedGenerationMethods': ['embedContent', 'countTextTokens', 'countTokens']}, {'name': 'models/gemini-embedding-001', 'version': '001', 'displayName': 'Gemini Embedding 001', 'description': 'Obtain a distributed representation of a text.', 'inputTokenLimit': 2048, 'outputTokenLimit': 1, 'supportedGenerationMethods': ['embedContent', 'countTextTokens', 'countTokens']}, {'name': 'models/aqa', 'version': '001', 'displayName': 'Model that performs Attributed Question Answering.', 'description': 'Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.', 'inputTokenLimit': 7168, 'outputTokenLimit': 1024, 'supportedGenerationMethods': ['generateAnswer'], 'temperature': 0.2, 'topP': 1, 'topK': 40}, {'name': 'models/imagen-3.0-generate-002', 'version': '002', 'displayName': 'Imagen 3.0', 'description': 'Vertex served Imagen 3.0 002 model', 'inputTokenLimit': 480, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['predict']}, {'name': 'models/imagen-4.0-generate-preview-06-06', 'version': '01', 'displayName': 'Imagen 4 (Preview)', 'description': 'Vertex served Imagen 4.0 model', 'inputTokenLimit': 480, 'outputTokenLimit': 8192, 'supportedGenerationMethods': ['predict']}], 'nextPageToken': 'Cihtb2RlbHMvaW1hZ2VuLTQuMC1nZW5lcmF0ZS1wcmV2aWV3LTA2LTA2'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "GEMINI_API_KEY = \"AIzaSyC-G81Hhcw9HduAmGboYXBgDx_szPcNqLk\"\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models?key={GEMINI_API_KEY}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    models = response.json()\n",
    "    print(models)\n",
    "else:\n",
    "    print(\"Error:\", response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
